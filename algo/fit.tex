\documentclass[aps,12pt]{revtex4}
\usepackage[a4paper]{geometry}
\usepackage{graphicx}
\usepackage{amssymb,amsfonts,amsmath,amsthm}
\usepackage{bm}
\usepackage{pslatex}
\usepackage{chemarr}
\usepackage{mathptmx}
\usepackage{bookman}

  	 
\begin{document}

\section{Single Sample}
We define a sample $\mathcal{S}_i$ 
by a set of $N_i$ \emph{scalar abscissae} $X_{ij}$ with corresponding \emph{vectorial ordinates} $\vec{Y}_{ij}$ of $\mathbb{R}^d$.

We want to fit this sample by a \emph{vectorial function of scalar variable} $\vec{F}$ which depends on a set of parameters $\vec{a}\in\mathbb{R}^M$.

We define the distance over $\mathcal{S}_i$:
\begin{equation}
	D^2_i = \dfrac{1}{2}\sum_{j=1}^{N_i} \left[ \vec{Y}_{ij} - \vec{F}(X_{ij},\vec{a})\right]^2
\end{equation}

\begin{equation}
	D^2_i(\vec{a}+\delta\vec{a}) \simeq D^2_i(\vec{a}) + \langle \vec{\nabla}_{\vec{a}} D^2_i \vert \delta \vec{a} \rangle
	+ \dfrac{1}{2} \langle \delta\vec{a} \vert \mathcal{H}_i \vert \delta \vec{a} \rangle
\end{equation}
The minimum is around the solution of:
\begin{equation}
	\bm{\alpha}_i   \delta \vec{a}  \simeq -\vec{\nabla}_{\vec{a}} D^2_i = \vec{\beta}_i
\end{equation}

\begin{equation}
	 \partial_{a_k}D^2_i = -\sum_{j=1}^{N_i} \left[ \vec{Y}_{ij} - \vec{F}(X_{ij},\vec{a})\right] \cdot \partial_{a_k}\vec{F}(X_{ij},\vec{a})
\end{equation}

\begin{equation}
	\alpha_{ikl} = \partial_{a_l,a_k} D^2_i 
	= \sum_{j=1}^{N_i} \left(
	\partial_{a_k}\vec{F}(X_{ij},\vec{a}) \cdot \partial_{a_l}\vec{F}(X_{ij},\vec{a})
	- \left[ \vec{Y}_{ij} - \vec{F}(X_{ij},\vec{a})\right] \partial_{a_l,a_k}\cdot\vec{F}(X_{ij},\vec{a})  \right)
\end{equation}

\begin{equation}
	\beta_{ik} = \sum_{j=1}^{N_i} \left[ \vec{Y}_{ij} - \vec{F}(X_{ij},\vec{a})\right] \cdot \partial_{a_k}\vec{F}(X_{ij},\vec{a})
\end{equation}

\section{Multiple Samples}
Let us combine $S$ samples with natural respective weights $N_i$:
\begin{equation}
	 D^2(\vec{a}) = \left(\sum_{i=1}^S N_i D^2_i(\vec{a}) \right) /  \left(\sum_{i=1}^S N_i \right)
\end{equation}
We get:
\begin{equation}
	\vec{\beta} = 1/\left(\sum_{i=1}^S N_i \right) \left( \sum_{i=1}^S N_i \vec{\beta}_i\right)
\end{equation}
and
\begin{equation}
		 \bm{\alpha} = 1/\left(\sum_{i=1}^S N_i \right) \left( \sum_{i=1}^S N_i \bm{\alpha}_i\right)
\end{equation}

\section{Decreasing}

\begin{equation}
	 D^2(\vec{a} + \delta \vec{a}) \simeq 
	  D^2(\vec{a}) - \langle \vec{\beta} \vert \delta\vec{a} \rangle 
	  + \dfrac{1}{2} \langle \delta\vec{a} \vert \bm{\alpha}  \vert \delta\vec{a} \rangle 
\end{equation}


\begin{equation}
	\bm{\alpha}_\lambda =
	\left\lbrace
	\begin{array}{ccl}
	\underbrace{\alpha_{ii}}_{\geq0}(1+w_i\lambda) & \iff & i=j\\
	\alpha_{ij} & \iff & i \not= j \\
	\end{array}
	\right.
\end{equation}

The guess step is:
\begin{equation}
	\delta \vec{a}_\lambda = \bm{\alpha}_\lambda^{-1} \vec \beta
\end{equation}

\begin{equation}
	\delta \vec{a}_\lambda \to 
	\dfrac{1}{\lambda}
	\begin{bmatrix}
		\vdots\\
		\dfrac{ \beta_i }{w_i\alpha_{ii}}\\
		\vdots\\
	\end{bmatrix}
\end{equation}

\section{Errors}
For no error, we have $\vec{a}_0$ and $D^2(\vec{a}_0)=0$.
With error, we have $\vec{a}_0+\delta\vec{a}$ and 
\begin{equation}
D^2(\vec{a}_0+\delta\vec{a})=D^2(\vec{a}_0) - \vec{\beta}_0 \cdot \delta\vec{a} + \frac{1}{2} 
\langle \delta \vec{a} \vert \bm{\alpha}_0 \vert \delta \vec{a}\rangle
\end{equation}


\end{document}
